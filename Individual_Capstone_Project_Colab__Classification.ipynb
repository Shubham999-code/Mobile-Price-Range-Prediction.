{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkWyQPLmQgNmR72Tx/4Hzm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubham999-code/Mobile-Price-Range-Prediction./blob/main/Individual_Capstone_Project_Colab__Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name** :- Mobile Price Range Prediction."
      ],
      "metadata": {
        "id": "YyGq5aYOZWs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Type** :- Classification.\n",
        "\n",
        "**Contribution** :- Team(Data Pirates)\n",
        "\n",
        "**Team Member 1 :-Tabassum Patel (Team Leader)**\n",
        "\n",
        "**Team Member 2 :-Shubham Kodape**\n",
        "\n",
        "**Team Member 3 :-Asma Patel**\n",
        "\n",
        "**Team Member 4 :-anuja Ghotekar**\n",
        "\n",
        "**Team Member 5 :-Pratiksha Auti** "
      ],
      "metadata": {
        "id": "x9Lkay5MZyxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary :-**"
      ],
      "metadata": {
        "id": "wpLPbVrra3WZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ml.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "tbrV-9XTbIoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now a days, a cellphone is an essential accessory of a person. It is the fastest evolving and moving product in the technology market space. New mobiles with updated versions and new features are introduced into the market at a rapid pace. Thousands of mobiles are sold each day. In such a fast-paced and volatile market, a mobile company needs to set optimal prices to complete with its rivals.This kind of prediction will help companies estimate price of mobiles to give tough competion to other mobile manufacturer.Also it will be usefull for Consumers to verify that they are paying best price for a mobile.\n",
        "\n",
        "In this project, we are going to explore and analyze a dataset which contains specifications of two thousand mobile phones and try to predict optimum price ranges for a list of mobile phones in the market.During the purchase of mobile phones, various features like memory, display, battery, camera, etc., are considered. People fail to make correct decisions, due to the non-availability of necessary resources to cross-validate the price. To address this issue, a machine learning model is developed using the data related to the key features of the mobile phone. The developed model is then used to predict the price range of the new mobile phone.use the machine learning algorithms namely Support Vector Machine (SVM), Random Forest Classifier (RFC), Logistic Regression,Decission Tree,Naive Bayes Theorm,K-nearest neighbors are used to train the model and predict the output as low, medium, high or very high of price range."
      ],
      "metadata": {
        "id": "1l-oVpgNbbTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link :-**"
      ],
      "metadata": {
        "id": "svti-DK8bh3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Shubham999-code"
      ],
      "metadata": {
        "id": "Z-rEICIZbrjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement :-**"
      ],
      "metadata": {
        "id": "wliL1YPBbvwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive mobile phone market companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phoneleg - RAM Internal Memory, etc) and its selling price in this problem, we do not have to predict the actual price but a price range indicating how high the price is ?\n",
        "\n",
        "AIM :- In this Project,On the basis of the mobile Specification like Battery power, 3G enabled , wifi ,Bluetooth, Ram etc we are predicting Price range of the mobile."
      ],
      "metadata": {
        "id": "cRv6JR5pbz4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Begin ! :-**"
      ],
      "metadata": {
        "id": "cDflSoUTb7S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Know Your Data :-**"
      ],
      "metadata": {
        "id": "Sv8OSAzdcBMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, import all required libraries like pandas, matplotlib, etc. These libraries are used to load, preprocess and visualize the dataset.\n",
        "\n",
        "Then load the training and testing dataset using the read_csv function of the pandas module and store into the separate variable train and test."
      ],
      "metadata": {
        "id": "vD8UErHtcG_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries :-**"
      ],
      "metadata": {
        "id": "bfXzF1uxcKfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VkrSWrKoVUXs"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Loading :-**"
      ],
      "metadata": {
        "id": "LH3BrQaccg_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-psNsJJrclTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa011078-2daa-41be-b758-12a065c9415c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/data_mobile_price_range.csv',encoding='unicode_escape')"
      ],
      "metadata": {
        "id": "1lWJQ2rRcu6s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset First View :-**"
      ],
      "metadata": {
        "id": "oMhVzq-Mcymk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "Ftg6-zMkc5jD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2e31fd57-3bfd-4c57-fea6-9a5b3fdc1234"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
              "0            842     0          2.2         0   1       0           7    0.6   \n",
              "1           1021     1          0.5         1   0       1          53    0.7   \n",
              "2            563     1          0.5         1   2       1          41    0.9   \n",
              "3            615     1          2.5         0   0       0          10    0.8   \n",
              "4           1821     1          1.2         0  13       1          44    0.6   \n",
              "\n",
              "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
              "0        188        2  ...         20       756  2549     9     7         19   \n",
              "1        136        3  ...        905      1988  2631    17     3          7   \n",
              "2        145        5  ...       1263      1716  2603    11     2          9   \n",
              "3        131        6  ...       1216      1786  2769    16     8         11   \n",
              "4        141        2  ...       1208      1212  1411     8     2         15   \n",
              "\n",
              "   three_g  touch_screen  wifi  price_range  \n",
              "0        0             0     1            1  \n",
              "1        1             1     0            2  \n",
              "2        1             1     0            2  \n",
              "3        1             0     0            2  \n",
              "4        1             1     0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cb0065b-d7ea-4f37-b428-652ab71009db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>756</td>\n",
              "      <td>2549</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>905</td>\n",
              "      <td>1988</td>\n",
              "      <td>2631</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0.9</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1263</td>\n",
              "      <td>1716</td>\n",
              "      <td>2603</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>131</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1216</td>\n",
              "      <td>1786</td>\n",
              "      <td>2769</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1821</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1208</td>\n",
              "      <td>1212</td>\n",
              "      <td>1411</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cb0065b-d7ea-4f37-b428-652ab71009db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cb0065b-d7ea-4f37-b428-652ab71009db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cb0065b-d7ea-4f37-b428-652ab71009db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Rows & Columns count :-**"
      ],
      "metadata": {
        "id": "YW6KMD-6dASL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "L8qN50kcdHLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38659a82-0eb5-47d2-b151-b3947e8d5823"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Information :-**"
      ],
      "metadata": {
        "id": "cr5NTqrvdP3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "eq_z4VKWdLSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22bffef-b388-4dd0-875a-26fbb398da26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   battery_power  2000 non-null   int64  \n",
            " 1   blue           2000 non-null   int64  \n",
            " 2   clock_speed    2000 non-null   float64\n",
            " 3   dual_sim       2000 non-null   int64  \n",
            " 4   fc             2000 non-null   int64  \n",
            " 5   four_g         2000 non-null   int64  \n",
            " 6   int_memory     2000 non-null   int64  \n",
            " 7   m_dep          2000 non-null   float64\n",
            " 8   mobile_wt      2000 non-null   int64  \n",
            " 9   n_cores        2000 non-null   int64  \n",
            " 10  pc             2000 non-null   int64  \n",
            " 11  px_height      2000 non-null   int64  \n",
            " 12  px_width       2000 non-null   int64  \n",
            " 13  ram            2000 non-null   int64  \n",
            " 14  sc_h           2000 non-null   int64  \n",
            " 15  sc_w           2000 non-null   int64  \n",
            " 16  talk_time      2000 non-null   int64  \n",
            " 17  three_g        2000 non-null   int64  \n",
            " 18  touch_screen   2000 non-null   int64  \n",
            " 19  wifi           2000 non-null   int64  \n",
            " 20  price_range    2000 non-null   int64  \n",
            "dtypes: float64(2), int64(19)\n",
            "memory usage: 328.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Duplicate Values :-**"
      ],
      "metadata": {
        "id": "c0JttwyOeCdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df1[df1.duplicated()])"
      ],
      "metadata": {
        "id": "HztR3oEReGh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f6988b-7628-48a9-f1d7-caf000ebe574"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Missing Values/Null Values :-**"
      ],
      "metadata": {
        "id": "TlRjiAz4eKbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df1.isnull().sum())"
      ],
      "metadata": {
        "id": "wNVp-sFUePhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ddbc0c-1605-485c-ef54-478d8efc8ace"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "battery_power    0\n",
            "blue             0\n",
            "clock_speed      0\n",
            "dual_sim         0\n",
            "fc               0\n",
            "four_g           0\n",
            "int_memory       0\n",
            "m_dep            0\n",
            "mobile_wt        0\n",
            "n_cores          0\n",
            "pc               0\n",
            "px_height        0\n",
            "px_width         0\n",
            "ram              0\n",
            "sc_h             0\n",
            "sc_w             0\n",
            "talk_time        0\n",
            "three_g          0\n",
            "touch_screen     0\n",
            "wifi             0\n",
            "price_range      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(df1.isnull(), cbar=False)\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "jeAWVErseTXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "d6e6598a-aca2-470f-cb80-063380c71d04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What did you know about your dataset?**"
      ],
      "metadata": {
        "id": "uV2Ppkq1ebFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer :- 1.The given dataset from competitive mobile market companies, and we do not have to predict the actual price but a price range indicating how high the price is.\n",
        "\n",
        "2.Mobile phones come in all sorts of prices, features, specifications and all. Price estimation and prediction is an important part of consumer strategy. Deciding on the correct price of a product is very important for the market success of a product. A new product that has to be launched, must have the correct price so that consumers find it appropriate to buy the product.\n",
        "\n",
        "3.The above dataset has 2000 rows and 21 columns. There are no mising values and duplicate values in the dataset."
      ],
      "metadata": {
        "id": "IccAoqX-ek67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Understanding Your Variables :-**"
      ],
      "metadata": {
        "id": "5bpoPOZoeqSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "EHY4Vtrlev9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766503a2-19b4-414b-fd30-82c02a946a1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
              "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
              "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
              "       'touch_screen', 'wifi', 'price_range'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.describe(include='all')"
      ],
      "metadata": {
        "id": "nk9dUJ28e2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d86d768e-5f48-4a4c-a718-a008d416920f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
              "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
              "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
              "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
              "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
              "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
              "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
              "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
              "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
              "\n",
              "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
              "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
              "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
              "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
              "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
              "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
              "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
              "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
              "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
              "\n",
              "         px_height     px_width          ram         sc_h         sc_w  \\\n",
              "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
              "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
              "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
              "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
              "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
              "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
              "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
              "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
              "\n",
              "         talk_time      three_g  touch_screen         wifi  price_range  \n",
              "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
              "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
              "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
              "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
              "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
              "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
              "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
              "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ee5e136-476d-4577-814b-06b586ba73c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.0000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1238.518500</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>1.522250</td>\n",
              "      <td>0.509500</td>\n",
              "      <td>4.309500</td>\n",
              "      <td>0.521500</td>\n",
              "      <td>32.046500</td>\n",
              "      <td>0.501750</td>\n",
              "      <td>140.249000</td>\n",
              "      <td>4.520500</td>\n",
              "      <td>...</td>\n",
              "      <td>645.108000</td>\n",
              "      <td>1251.515500</td>\n",
              "      <td>2124.213000</td>\n",
              "      <td>12.306500</td>\n",
              "      <td>5.767000</td>\n",
              "      <td>11.011000</td>\n",
              "      <td>0.761500</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>439.418206</td>\n",
              "      <td>0.5001</td>\n",
              "      <td>0.816004</td>\n",
              "      <td>0.500035</td>\n",
              "      <td>4.341444</td>\n",
              "      <td>0.499662</td>\n",
              "      <td>18.145715</td>\n",
              "      <td>0.288416</td>\n",
              "      <td>35.399655</td>\n",
              "      <td>2.287837</td>\n",
              "      <td>...</td>\n",
              "      <td>443.780811</td>\n",
              "      <td>432.199447</td>\n",
              "      <td>1084.732044</td>\n",
              "      <td>4.213245</td>\n",
              "      <td>4.356398</td>\n",
              "      <td>5.463955</td>\n",
              "      <td>0.426273</td>\n",
              "      <td>0.500116</td>\n",
              "      <td>0.500076</td>\n",
              "      <td>1.118314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>501.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>851.750000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>282.750000</td>\n",
              "      <td>874.750000</td>\n",
              "      <td>1207.500000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1226.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1247.000000</td>\n",
              "      <td>2146.500000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1615.250000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>947.250000</td>\n",
              "      <td>1633.000000</td>\n",
              "      <td>3064.500000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1998.000000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1960.000000</td>\n",
              "      <td>1998.000000</td>\n",
              "      <td>3998.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee5e136-476d-4577-814b-06b586ba73c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ee5e136-476d-4577-814b-06b586ba73c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ee5e136-476d-4577-814b-06b586ba73c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total phones with sc_w = 0\n",
        "print(len(df1[df1.sc_w == 0]))\n",
        "# Total phones with px_height = 0\n",
        "print(len(df1[df1.px_height == 0]))"
      ],
      "metadata": {
        "id": "GTFLl0fDe7nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6034d1-5055-4d99-dc64-ac43487f2fb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#where ther is sc_W and px_height is zero ,assigning mean values\n",
        "df1['sc_w'][df1[df1.sc_w == 0].index] = df1.sc_w.mean()\n",
        "df1['px_height'][df1[df1.px_height == 0].index] = df1.px_height.mean()"
      ],
      "metadata": {
        "id": "fJa7XJdJe_0F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking whether there is duplicates or not\n",
        "len(df1[df1.duplicated()])"
      ],
      "metadata": {
        "id": "4j7wLwrFfEB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82519cec-337d-419c-c7c0-4d5c3fea722c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The nunique () method returns the number of unique values for each column\n",
        "df1.nunique()"
      ],
      "metadata": {
        "id": "wDECyZKvfJGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7fa0e0-7cfc-42ee-91a5-15d73836f4e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "battery_power    1094\n",
              "blue                2\n",
              "clock_speed        26\n",
              "dual_sim            2\n",
              "fc                 20\n",
              "four_g              2\n",
              "int_memory         63\n",
              "m_dep              10\n",
              "mobile_wt         121\n",
              "n_cores             8\n",
              "pc                 21\n",
              "px_height        1137\n",
              "px_width         1109\n",
              "ram              1562\n",
              "sc_h               15\n",
              "sc_w               19\n",
              "talk_time          19\n",
              "three_g             2\n",
              "touch_screen        2\n",
              "wifi                2\n",
              "price_range         4\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**there are no duplicate values.**"
      ],
      "metadata": {
        "id": "tcgxlJyvfNCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking whether there is null values or not\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "Svjhlx4YfUL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a76a37-86b8-4f84-bb8e-0f0704cf1b1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "battery_power    0\n",
              "blue             0\n",
              "clock_speed      0\n",
              "dual_sim         0\n",
              "fc               0\n",
              "four_g           0\n",
              "int_memory       0\n",
              "m_dep            0\n",
              "mobile_wt        0\n",
              "n_cores          0\n",
              "pc               0\n",
              "px_height        0\n",
              "px_width         0\n",
              "ram              0\n",
              "sc_h             0\n",
              "sc_w             0\n",
              "talk_time        0\n",
              "three_g          0\n",
              "touch_screen     0\n",
              "wifi             0\n",
              "price_range      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**there are no missing values in the data set.**"
      ],
      "metadata": {
        "id": "ZoC6Lx16ff99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables Description :-**"
      ],
      "metadata": {
        "id": "506c9caWfkOs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Battery_power : Total energy a battery can store in one time measured in mAh\n",
        "\n",
        "*   Blue : Has bluetooth or not\n",
        "*   Clock_speed : speed at which microprocessor executes instructions\n",
        "*   Dual_sim : Has dual sim support or not\n",
        "*   Fc : Front Camera mega pixels\n",
        "*   Four_g : Has 4G or not\n",
        "*   Int_memory : Internal Memory in Gigabytes\n",
        "*   M_dep : Mobile Depth in cm\n",
        "*   Mobile_wt : Weight of mobile phone\n",
        "*   N_cores : Number of cores of processor\n",
        "*   Pc : Primary Camera mega pixels\n",
        "*   Px_height : Pixel Resolution Height\n",
        "*   Px_width : Pixel Resolution Width\n",
        "*   Ram : Random Access Memory in Mega\n",
        "*   Touch_screen : Has touch screen or not\n",
        "*   Wifi : Has wifi or not\n",
        "*   Sc_h : Screen Height of mobile in cm\n",
        "*   Sc_w : Screen Width of mobile in cm\n",
        "*   Talk_time : longest time that a single battery charge will last when you are\n",
        "*   Three_g : Has 3G or not\n",
        "*   Wifi : Has wifi or not\n",
        "*   Price_range : This is the target variable with value of 0(low cost),      (medium cost),2(high cost) and 3(very high cost)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Unique Values for each variable. :-**"
      ],
      "metadata": {
        "id": "dYV54weKgDoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df1.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df1[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "7U6cWnFUgMgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f6bba5-1cd4-4736-d7be-caca413d730e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of unique values in  battery_power is 1094 .\n",
            "No. of unique values in  blue is 2 .\n",
            "No. of unique values in  clock_speed is 26 .\n",
            "No. of unique values in  dual_sim is 2 .\n",
            "No. of unique values in  fc is 20 .\n",
            "No. of unique values in  four_g is 2 .\n",
            "No. of unique values in  int_memory is 63 .\n",
            "No. of unique values in  m_dep is 10 .\n",
            "No. of unique values in  mobile_wt is 121 .\n",
            "No. of unique values in  n_cores is 8 .\n",
            "No. of unique values in  pc is 21 .\n",
            "No. of unique values in  px_height is 1137 .\n",
            "No. of unique values in  px_width is 1109 .\n",
            "No. of unique values in  ram is 1562 .\n",
            "No. of unique values in  sc_h is 15 .\n",
            "No. of unique values in  sc_w is 19 .\n",
            "No. of unique values in  talk_time is 19 .\n",
            "No. of unique values in  three_g is 2 .\n",
            "No. of unique values in  touch_screen is 2 .\n",
            "No. of unique values in  wifi is 2 .\n",
            "No. of unique values in  price_range is 4 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Now start wih Machine Learning algorithim :-**"
      ],
      "metadata": {
        "id": "upC27tuUgmKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all libraries\n",
        "from sklearn.metrics import confusion_matrix ,classification_report,precision_score, recall_score ,f1_score, roc_auc_score,accuracy_score \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "!pip install shap==0.40.0\n",
        "import shap \n",
        "import graphviz\n",
        "sns.set_style('darkgrid') "
      ],
      "metadata": {
        "id": "QI3pHcyWgr_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868f060e-0881-46bc-9745-a205945ba7c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap==0.40.0\n",
            "  Downloading shap-0.40.0-cp39-cp39-manylinux2010_x86_64.whl (567 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.6/567.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (23.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (2.2.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (1.5.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (0.56.4)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from shap==0.40.0) (1.2.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->shap==0.40.0) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->shap==0.40.0) (67.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap==0.40.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->shap==0.40.0) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap==0.40.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->shap==0.40.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->shap==0.40.0) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Selection with hypothesis test :-**"
      ],
      "metadata": {
        "id": "3WWa6uLgjmHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-test: It is help to figure-out relation between features and label with \"pvalue <= 0.1\""
      ],
      "metadata": {
        "id": "KmfWQ-Y8jrmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct = pd.crosstab(df1['wifi'],df1['price_range'])\n",
        "from scipy.stats import chi2_contingency\n",
        "stat,pvalue,dof,expected_R = chi2_contingency(ct)\n",
        "print(\"pvalue : \",pvalue)\n",
        "\n",
        "if pvalue <= 0.1:\n",
        "    print(\"Alternate Hypothesis passed. int_memory and price_range have Relationship\")\n",
        "else:\n",
        "    print(\"Null hypothesis passed. int_memory and price_range doesnot have  Relationship\")"
      ],
      "metadata": {
        "id": "ae0j_CJMjo9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ea1cd5-d05d-4b9c-f844-4d8dd57f89fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pvalue :  0.8359905195342198\n",
            "Null hypothesis passed. int_memory and price_range doesnot have  Relationship\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  defining new variable for pixels\n",
        "data_num = df1[['battery_power',  'clock_speed' , 'fc','int_memory','m_dep', 'mobile_wt','n_cores', 'pc',\n",
        "                      'px_height','px_width','ram', 'sc_h', 'sc_w', 'talk_time']]\n",
        "\n",
        "df1['pixels'] = data_num['px_height']*data_num['px_width']\n",
        "# Dropping px_height and px_width\n",
        "\n",
        "df1.drop(['px_height', 'px_width'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "i8g7OpUmjzma"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining X and y\n",
        "x = df1.drop(['price_range'], axis = 1).values\n",
        "y = df1['price_range'].values"
      ],
      "metadata": {
        "id": "9I9W7cZUlMyh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "-xjfRe9MlQLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caab0f9b-e13f-4c7d-c599-877587d45358"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "VbyAklzJlT3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d37650f-7768-469e-87d3-ec6298349ab7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling values of X\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "JalWjt7jlX49"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model Implementation :-**"
      ],
      "metadata": {
        "id": "oPi-WCK2l4GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we will be using many algorithms and compare all of them. which algorithm will be giving us a Better result. The following algorithms are below.\n",
        "\n",
        "1.support vector classification\n",
        "\n",
        "2.DecisionTreeClassifier\n",
        "\n",
        "3.RandomForestClassifier\n",
        "\n",
        "4.XGB boostclassifier"
      ],
      "metadata": {
        "id": "0xd-G5q9lrwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **spliting training and testing data :-**"
      ],
      "metadata": {
        "id": "BtwU90r7lbJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separate the dataset in two type one trainingis 75% of data and other testing is 25% of data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.25, random_state=167)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "1H6PuH9_leqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b065b27a-8951-4ea9-f961-3f5304091561"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 19)\n",
            "(500, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model 4 - implementing support vector machine classifier :-**"
      ],
      "metadata": {
        "id": "cWyFxmOjjKtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying support vector machine classifier\n",
        "svcmodel = SVC(probability=True)  \n",
        "svcmodel.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "inuPRwz5jRKc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8e2a8eef-7d24-43c8-b220-d2655ff78ff0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainscore =  svcmodel.score(x_train,y_train)\n",
        "testscore =  svcmodel.score(x_test,y_test)  \n",
        "\n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {} \".format(testscore),'\\n')\n",
        "y_predsvc =  svcmodel.predict(x_test)\n",
        "print(' f1 score: ',f1_score(y_test, y_predsvc,average='micro'),'\\n')\n",
        "print(confusion_matrix(y_test, y_predsvc))"
      ],
      "metadata": {
        "id": "FZenrbVYmFvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1967634b-076d-45df-e6bd-5422143624bd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.954 \n",
            "\n",
            "test score: 0.844  \n",
            "\n",
            " f1 score:  0.844 \n",
            "\n",
            "[[114  18   0   0]\n",
            " [  8  92   9   0]\n",
            " [  0  12  97  10]\n",
            " [  0   0  21 119]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' precision score: ',precision_score(y_test, y_predsvc,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_predsvc,average='micro'),'\\n')\n",
        "print(classification_report(y_test, y_predsvc))"
      ],
      "metadata": {
        "id": "XVPyV4fOmI7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6a1f00-8306-4df5-d26b-c82a8ffb36ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " precision score:  0.844 \n",
            "\n",
            " recall score:  0.844 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.86      0.90       132\n",
            "           1       0.75      0.84      0.80       109\n",
            "           2       0.76      0.82      0.79       119\n",
            "           3       0.92      0.85      0.88       140\n",
            "\n",
            "    accuracy                           0.84       500\n",
            "   macro avg       0.84      0.84      0.84       500\n",
            "weighted avg       0.85      0.84      0.85       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------- support vector classification -------------------------------------\n",
        "probabilityValues = svcmodel.predict_proba(x)\n",
        "auc = roc_auc_score(y,probabilityValues,multi_class ='ovr')\n",
        "print(auc)\n",
        "     "
      ],
      "metadata": {
        "id": "eYTGuWY5mMcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d65f19c-0a94-40c2-ab95-237e1169fce7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9932946666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finally we made result in support vector machine!!**"
      ],
      "metadata": {
        "id": "CTMDi_WbmRqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "KFnbHHjkmVdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :-\n",
        "\n",
        "1.we used support vector machine to create the model. As we got not so good result.\n",
        "\n",
        "2.For training score is 95% and testing score 83%\n",
        "\n",
        "3.For testing dataset, i found precision of 83% and recall of 83% and f1-score of 83% . BUt, we also interested to see the result for mobile price range result as\n",
        "\n",
        "a.we got low(0) price precision 96% of and recall of 83% and f1-score of 89%.\n",
        "\n",
        "b.we got medium(1) price precision 73% of and recall of 81% and f1-score of 77%.\n",
        "\n",
        "c.we got High(2) price precision 74% of and recall of 81% and f1-score of 77%.\n",
        "\n",
        "d.we got very high(3) price precision 92% of and recall of 85% and f1-score of 88%."
      ],
      "metadata": {
        "id": "T6u_gufombiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model 5 - implementing Decision Tree :-**"
      ],
      "metadata": {
        "id": "cNajSfkOmira"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Decision Tree\n",
        "DTmodel=  DecisionTreeClassifier(max_depth=6)  \n",
        "DTmodel.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "NrpHUMfymnaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "b0b53114-4303-40f0-edf5-54d54eeb74cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=6)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainscore =  DTmodel.score(x_train,y_train)\n",
        "testscore =  DTmodel.score(x_test,y_test)\n",
        "y_predDT =  DTmodel.predict(x_test)\n",
        "\n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {} \".format(testscore),'\\n')\n",
        "print(' f1 score: ',f1_score(y_test, y_predDT,average='micro'),'\\n')\n",
        "print(confusion_matrix(y_test, y_predDT))"
      ],
      "metadata": {
        "id": "SZu91ah6mqmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7789ceb-9bab-4efc-8c8b-24985ba8ab0e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.93 \n",
            "\n",
            "test score: 0.854  \n",
            "\n",
            " f1 score:  0.854 \n",
            "\n",
            "[[115  17   0   0]\n",
            " [  1  95  13   0]\n",
            " [  0  15  91  13]\n",
            " [  0   0  14 126]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' precision score: ',precision_score(y_test, y_predDT,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_predDT,average='micro'),'\\n')\n",
        "print(classification_report(y_test, y_predDT))"
      ],
      "metadata": {
        "id": "sV0Lz29CmutB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1533b2-e3eb-40d8-f402-ae753656e726"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " precision score:  0.854 \n",
            "\n",
            " recall score:  0.854 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.87      0.93       132\n",
            "           1       0.75      0.87      0.81       109\n",
            "           2       0.77      0.76      0.77       119\n",
            "           3       0.91      0.90      0.90       140\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.85      0.85      0.85       500\n",
            "weighted avg       0.86      0.85      0.86       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------- Decision Tree -------------------------------------\n",
        "probabilityValues = DTmodel.predict_proba(x)\n",
        "auc = roc_auc_score(y,probabilityValues,multi_class ='ovr')\n",
        "print(auc)\n",
        "     "
      ],
      "metadata": {
        "id": "GMj14ce9mx2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a568d51-59fb-44b4-947b-c21cbd6818e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9779121666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finally we made result in Decision Tree!!**"
      ],
      "metadata": {
        "id": "3uCBgcT7m4lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "CluPyMXOm_MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer : -\n",
        "\n",
        "1.we used Decision Tree to create the model. As we got not so good result.\n",
        "\n",
        "2.For training score is 93% and testing score 85%\n",
        "\n",
        "3.For testing dataset, i found precision of 85% and recall of 85% and f1-score of 85% . BUt, we also interested to see the result for mobile price range result as\n",
        "\n",
        "a.we got low(0) price precision 99% of and recall of 86% and f1-score of 92%.\n",
        "\n",
        "b.we got medium(1) price precision 74% of and recall of 87% and f1-score of 80%.\n",
        "\n",
        "c.we got High(2) price precision 79% of and recall of 77% and f1-score of 78%.\n",
        "\n",
        "d.we got very high(3) price precision 91% of and recall of 91% and f1-score of 91%."
      ],
      "metadata": {
        "id": "1dP7twOonDzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gridDT = GridSearchCV(DTmodel, param_grid = {'max_depth': (5, 30), 'max_leaf_nodes': (10, 100)}, scoring = 'accuracy', cv = 5, verbose = 24)\n",
        "gridDT.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "JAk6qrpQnJOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "960b2533-6cac-4e7b-b74e-a2f413ec6fb4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START max_depth=5, max_leaf_nodes=10..............................\n",
            "[CV 1/5; 1/4] END max_depth=5, max_leaf_nodes=10;, score=0.777 total time=   0.0s\n",
            "[CV 2/5; 1/4] START max_depth=5, max_leaf_nodes=10..............................\n",
            "[CV 2/5; 1/4] END max_depth=5, max_leaf_nodes=10;, score=0.783 total time=   0.0s\n",
            "[CV 3/5; 1/4] START max_depth=5, max_leaf_nodes=10..............................\n",
            "[CV 3/5; 1/4] END max_depth=5, max_leaf_nodes=10;, score=0.837 total time=   0.0s\n",
            "[CV 4/5; 1/4] START max_depth=5, max_leaf_nodes=10..............................\n",
            "[CV 4/5; 1/4] END max_depth=5, max_leaf_nodes=10;, score=0.783 total time=   0.0s\n",
            "[CV 5/5; 1/4] START max_depth=5, max_leaf_nodes=10..............................\n",
            "[CV 5/5; 1/4] END max_depth=5, max_leaf_nodes=10;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 2/4] START max_depth=5, max_leaf_nodes=100.............................\n",
            "[CV 1/5; 2/4] END max_depth=5, max_leaf_nodes=100;, score=0.827 total time=   0.0s\n",
            "[CV 2/5; 2/4] START max_depth=5, max_leaf_nodes=100.............................\n",
            "[CV 2/5; 2/4] END max_depth=5, max_leaf_nodes=100;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 2/4] START max_depth=5, max_leaf_nodes=100.............................\n",
            "[CV 3/5; 2/4] END max_depth=5, max_leaf_nodes=100;, score=0.850 total time=   0.0s\n",
            "[CV 4/5; 2/4] START max_depth=5, max_leaf_nodes=100.............................\n",
            "[CV 4/5; 2/4] END max_depth=5, max_leaf_nodes=100;, score=0.837 total time=   0.0s\n",
            "[CV 5/5; 2/4] START max_depth=5, max_leaf_nodes=100.............................\n",
            "[CV 5/5; 2/4] END max_depth=5, max_leaf_nodes=100;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 3/4] START max_depth=30, max_leaf_nodes=10.............................\n",
            "[CV 1/5; 3/4] END max_depth=30, max_leaf_nodes=10;, score=0.777 total time=   0.0s\n",
            "[CV 2/5; 3/4] START max_depth=30, max_leaf_nodes=10.............................\n",
            "[CV 2/5; 3/4] END max_depth=30, max_leaf_nodes=10;, score=0.783 total time=   0.0s\n",
            "[CV 3/5; 3/4] START max_depth=30, max_leaf_nodes=10.............................\n",
            "[CV 3/5; 3/4] END max_depth=30, max_leaf_nodes=10;, score=0.837 total time=   0.0s\n",
            "[CV 4/5; 3/4] START max_depth=30, max_leaf_nodes=10.............................\n",
            "[CV 4/5; 3/4] END max_depth=30, max_leaf_nodes=10;, score=0.783 total time=   0.0s\n",
            "[CV 5/5; 3/4] START max_depth=30, max_leaf_nodes=10.............................\n",
            "[CV 5/5; 3/4] END max_depth=30, max_leaf_nodes=10;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 4/4] START max_depth=30, max_leaf_nodes=100............................\n",
            "[CV 1/5; 4/4] END max_depth=30, max_leaf_nodes=100;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 4/4] START max_depth=30, max_leaf_nodes=100............................\n",
            "[CV 2/5; 4/4] END max_depth=30, max_leaf_nodes=100;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 4/4] START max_depth=30, max_leaf_nodes=100............................\n",
            "[CV 3/5; 4/4] END max_depth=30, max_leaf_nodes=100;, score=0.833 total time=   0.0s\n",
            "[CV 4/5; 4/4] START max_depth=30, max_leaf_nodes=100............................\n",
            "[CV 4/5; 4/4] END max_depth=30, max_leaf_nodes=100;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 4/4] START max_depth=30, max_leaf_nodes=100............................\n",
            "[CV 5/5; 4/4] END max_depth=30, max_leaf_nodes=100;, score=0.843 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=6),\n",
              "             param_grid={'max_depth': (5, 30), 'max_leaf_nodes': (10, 100)},\n",
              "             scoring='accuracy', verbose=24)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=6),\n",
              "             param_grid={&#x27;max_depth&#x27;: (5, 30), &#x27;max_leaf_nodes&#x27;: (10, 100)},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=24)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=6),\n",
              "             param_grid={&#x27;max_depth&#x27;: (5, 30), &#x27;max_leaf_nodes&#x27;: (10, 100)},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=24)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find best params value\n",
        "gridDT.best_params_"
      ],
      "metadata": {
        "id": "e1W2H3AGnN4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea4fc70-5498-4bf3-81ef-cc63809e8622"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 5, 'max_leaf_nodes': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find best estimeter\n",
        "gridDT.best_estimator_"
      ],
      "metadata": {
        "id": "YuM9cyQSnQSH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "37230648-b0d1-472e-e120-f16442f15f90"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DTgmodel=DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)\n",
        "DTgmodel.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "LK3Ov_gwnS0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "bfc69389-23be-47ac-f828-617f243bc86d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "# Get the predicted probabilities\n",
        "trainscore =  DTgmodel.score(x_train,y_train)\n",
        "testscore =  DTgmodel.score(x_test,y_test) \n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {}\".format(testscore),'\\n')\n",
        "y_predgDT = DTgmodel.predict(x_test)\n",
        "print(' f1 score: ',f1_score(y_test, y_predgDT,average='micro'),'\\n')\n",
        "\n",
        "# Get the confusion matrix for both train and test\n",
        "print(confusion_matrix(y_test, y_predgDT))"
      ],
      "metadata": {
        "id": "VWIK5ey3nWFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba4b3d-2908-45d6-d95e-e68575287897"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.8913333333333333 \n",
            "\n",
            "test score: 0.848 \n",
            "\n",
            " f1 score:  0.848 \n",
            "\n",
            "[[114  18   0   0]\n",
            " [  2  98   9   0]\n",
            " [  0  17  85  17]\n",
            " [  0   0  13 127]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_pred_test = DTgmodel.predict(x_test)\n",
        "y_pres_train = DTgmodel.predict(x_train)\n",
        "\n",
        "# Evaluation metrics for test\n",
        "print(' precision score: ',precision_score(y_test, y_predgDT,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_predgDT,average='micro'),'\\n')\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "j29zOFaAnbP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7857072-888e-45dd-a7c2-2ee29931ef47"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " precision score:  0.848 \n",
            "\n",
            " recall score:  0.848 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.86      0.92       132\n",
            "           1       0.74      0.90      0.81       109\n",
            "           2       0.79      0.71      0.75       119\n",
            "           3       0.88      0.91      0.89       140\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.85      0.85      0.84       500\n",
            "weighted avg       0.86      0.85      0.85       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------- Decision Tree -------------------------------------\n",
        "probabilityValues = DTmodel.predict_proba(x)\n",
        "auc = roc_auc_score(y,probabilityValues,multi_class ='ovr')\n",
        "print(auc)"
      ],
      "metadata": {
        "id": "jHdCFmG9nfbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fedca83-a311-4c72-8e48-69fb4b366c6c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9779121666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "tF8NH85knh7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer :-\n",
        "\n",
        "GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "our goal should be to find the best hyperparameters values to get the perfect prediction results from our model. But the question arises, how to find these best sets of hyperparameters? One can try the Manual Search method, by using the hit and trial process and can find the best hyperparameters which would take huge time to build a single model.\n",
        "\n",
        "For this reason, methods like Random Search, GridSearch were introduced. Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved.\n",
        "\n",
        "In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n",
        "\n",
        "That's why we have used GridsearCV method for hyperparameter optimization.\n",
        "\n",
        "Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "For training score is 89% and testing score 84%.\n",
        "\n",
        "For testing dataset,\n",
        "\n",
        "a.we got low(0) price precision 98% of and recall of 86% and f1-score of 92%.\n",
        "\n",
        "b.we got medium(1) price precision 74% of and recall of 90% and f1-score of 81%.\n",
        "\n",
        "c.we got High(2) price precision 79% of and recall of 71% and f1-score of 75%.\n",
        "\n",
        "d.we got very high(3) price precision 88% of and recall of 91% and f1-score of 89%."
      ],
      "metadata": {
        "id": "A3Vaz2-KnnsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model 6 - implementing Random forest classifier :-**"
      ],
      "metadata": {
        "id": "r8oaNSp3nrU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying random forest classifier\n",
        "RFmodel=  RandomForestClassifier(criterion='entropy',max_depth=9) \n",
        "RFmodel.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "IB6Mwy-BnvUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "957db88f-97a7-4177-f98d-40523738ebb6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', max_depth=9)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainscore =  RFmodel.score(x_train,y_train)\n",
        "testscore =  RFmodel.score(x_test,y_test)  \n",
        "y_predRF =  RFmodel.predict(x_test)\n",
        "\n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {} \".format(testscore),'\\n')\n",
        "print(' f1 score: ',f1_score(y_test, y_predRF,average='micro'),'\\n')\n",
        "print(confusion_matrix(y_test, y_predRF))"
      ],
      "metadata": {
        "id": "4ABCULT2nyy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc47f05-d331-4aa0-a247-bad13fefa569"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.9993333333333333 \n",
            "\n",
            "test score: 0.864  \n",
            "\n",
            " f1 score:  0.864 \n",
            "\n",
            "[[121  11   0   0]\n",
            " [  4  95  10   0]\n",
            " [  0  16  87  16]\n",
            " [  0   0  11 129]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' precision score: ',precision_score(y_test, y_predRF,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_predRF,average='micro'),'\\n')\n",
        "print(classification_report(y_test, y_predRF))"
      ],
      "metadata": {
        "id": "2X_N0M5Tn16A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b3fb3c-1eec-4765-fdce-d708dcebc636"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " precision score:  0.864 \n",
            "\n",
            " recall score:  0.864 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94       132\n",
            "           1       0.78      0.87      0.82       109\n",
            "           2       0.81      0.73      0.77       119\n",
            "           3       0.89      0.92      0.91       140\n",
            "\n",
            "    accuracy                           0.86       500\n",
            "   macro avg       0.86      0.86      0.86       500\n",
            "weighted avg       0.87      0.86      0.86       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------- Random Forest -------------------------------------\n",
        "probabilityValues = RFmodel.predict_proba(x)\n",
        "auc = roc_auc_score(y,probabilityValues,multi_class ='ovr')\n",
        "print(auc)"
      ],
      "metadata": {
        "id": "haer8pdYn5OI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5134f18a-af6e-4276-cef1-ebab676ddb42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9975116666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_importance = pd.DataFrame({'Feature':x.columns,\n",
        "#                                   'Score':RFmodel.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "#feature_importance.head()"
      ],
      "metadata": {
        "id": "u_B0LnC6n8JY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph of features importance\n",
        "#fig, ax = plt.subplots(figsize=(15,8))\n",
        "#ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "YvwpB2Qun-qm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finally we made result in Random Forest classifier!!**"
      ],
      "metadata": {
        "id": "cKv7q4RFoBxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "lMqmWBIyoFXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.we used Random Forest classifier to create the model. As we got not so good result.\n",
        "\n",
        "2.For training score is 99% and testing score 86%\n",
        "\n",
        "3.For testing dataset, i found precision of 86% and recall of 86% and f1-score of 86% . BUt, we also interested to see the result for mobile price range result as\n",
        "\n",
        "a.we got low(0) price precision 97% of and recall of 91% and f1-score of 94%.\n",
        "\n",
        "b.we got medium(1) price precision 76% of and recall of 86% and f1-score of 81%.\n",
        "\n",
        "c.we got High(2) price precision 80% of and recall of 75% and f1-score of 77%.\n",
        "\n",
        "d.we got very high(3) price precision 91% of and recall of 92% and f1-score of 91"
      ],
      "metadata": {
        "id": "16ZDTsWWoIwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cross validation\n",
        "params = {'n_estimators':[10,50,100,200],\n",
        "          'max_depth':[10,20,30,40],\n",
        "          'min_samples_split':[2,4,6],\n",
        "         'max_features':['sqrt',4,'log2','auto'],\n",
        "         'max_leaf_nodes':[10, 20, 40]\n",
        "         }\n",
        "rf = RandomForestClassifier()\n",
        "rfgd = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "rfgd.fit(x, y)"
      ],
      "metadata": {
        "id": "-aWJGs70oL5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2b9afefe-4cd1-4744-bcb8-c583fab8166d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={'max_depth': [10, 20, 30, 40],\n",
              "                         'max_features': ['sqrt', 4, 'log2', 'auto'],\n",
              "                         'max_leaf_nodes': [10, 20, 40],\n",
              "                         'min_samples_split': [2, 4, 6],\n",
              "                         'n_estimators': [10, 50, 100, 200]},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, 40],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 4, &#x27;log2&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;max_leaf_nodes&#x27;: [10, 20, 40],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
              "                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, 40],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 4, &#x27;log2&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;max_leaf_nodes&#x27;: [10, 20, 40],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
              "                         &#x27;n_estimators&#x27;: [10, 50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyper_tuning of random_forest classifier**"
      ],
      "metadata": {
        "id": "GcTXn77FoQ9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find best params value\n",
        "rfgd.best_params_"
      ],
      "metadata": {
        "id": "XL8NTRU8oU2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4fdb46-1573-42f0-b5e6-ff02a6d8b6ee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 10,\n",
              " 'max_features': 4,\n",
              " 'max_leaf_nodes': 40,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find best estimeter\n",
        "rfgd.best_estimator_ "
      ],
      "metadata": {
        "id": "R8hynVmboXdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "64a1b639-8115-4766-b84f-f7bc91ed021a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, max_features=4, max_leaf_nodes=40)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=4, max_leaf_nodes=40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=4, max_leaf_nodes=40)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfgd = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "rfgd.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "9-ZbGP15oaS_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "fa53ee27-3828-4e8c-811d-b8fcc7e141c8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=30, max_features='log2', max_leaf_nodes=40,\n",
              "                       min_samples_split=4, n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=30, max_features=&#x27;log2&#x27;, max_leaf_nodes=40,\n",
              "                       min_samples_split=4, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, max_features=&#x27;log2&#x27;, max_leaf_nodes=40,\n",
              "                       min_samples_split=4, n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "\n",
        "y_pred_test = rfgd.predict(x_test)\n",
        "y_pres_train = rfgd.predict(x_train)\n",
        "# Evaluation metrics for test\n",
        "trainscore =  RFmodel.score(x_train,y_train)\n",
        "testscore =  RFmodel.score(x_test,y_test)  \n",
        "\n",
        "print('Classification Report for Decision Tree (Test set)= ')\n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {} \".format(testscore),'\\n')\n",
        "print(' precision score: ',precision_score(y_test, y_pred_test,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_pred_test,average='micro'),'\\n')\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "1OREz1Syod2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3609380-199f-4836-97c0-4b423e61942b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Decision Tree (Test set)= \n",
            "train score: 0.9993333333333333 \n",
            "\n",
            "test score: 0.864  \n",
            "\n",
            " precision score:  0.846 \n",
            "\n",
            " recall score:  0.846 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       132\n",
            "           1       0.78      0.83      0.80       109\n",
            "           2       0.75      0.67      0.71       119\n",
            "           3       0.87      0.91      0.89       140\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.84      0.84      0.84       500\n",
            "weighted avg       0.84      0.85      0.84       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#features importance \n",
        "#feature_importance = pd.DataFrame({'Feature':x.columns,\n",
        "                                   #'Score':rfgd.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "#feature_importance.head("
      ],
      "metadata": {
        "id": "WmdmmFiVogp0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph of features importance\n",
        "#fig, ax = plt.subplots(figsize=(15,8))\n",
        "#ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "JvyP-rsVoin8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model 7 - implementing XGBclassifier :-**"
      ],
      "metadata": {
        "id": "z30AXKs3ok7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "xgb.fit(x_train, y_train)\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')"
      ],
      "metadata": {
        "id": "wN6daCEHonxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "502a2660-8b1b-48cc-8eb1-e3c22f56373e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_pred_train = xgb.predict(x_train)\n",
        "y_pred_test = xgb.predict(x_test)\n",
        "\n",
        "# Evaluation metrics for test\n",
        "print('Train_score:',accuracy_score(y_train,y_pred_train),'\\n')\n",
        "print('test score:',accuracy_score(y_test,y_pred_test),'\\n')\n",
        "print(' precision score: ',precision_score(y_test, y_pred_test,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_pred_test,average='micro'),'\\n')\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "urRANrbloq5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07994e6f-fa2c-47d8-db39-b40f5adbfe56"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_score: 1.0 \n",
            "\n",
            "test score: 0.894 \n",
            "\n",
            " precision score:  0.894 \n",
            "\n",
            " recall score:  0.894 \n",
            "\n",
            "Classification Report for XGBoost(Test set)= \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94       132\n",
            "           1       0.80      0.94      0.86       109\n",
            "           2       0.87      0.79      0.83       119\n",
            "           3       0.92      0.94      0.93       140\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.89      0.89      0.89       500\n",
            "weighted avg       0.90      0.89      0.89       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finally we made result in XGB classifier!!**"
      ],
      "metadata": {
        "id": "XojrLDyTotrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "XvJSqMHgowQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer:-\n",
        "\n",
        "1.we used xgb classifier to create the model. As I got so good result.\n",
        "\n",
        "2.For training score is 100% and testing score 89%\n",
        "\n",
        "3.For testing dataset, i found precision of 89% and recall of 89% and f1-score of 89% . BUt, we also interested to see the result for mobile price range result as\n",
        "\n",
        "a.we got low(0) price precision 98% of and recall of 89% and f1-score of 94%.\n",
        "\n",
        "b.we got medium(1) price precision 80% of and recall of 94% and f1-score of 87%.\n",
        "\n",
        "c.we got High(2) price precision 88% of and recall of 80% and f1-score of 84%.\n",
        "\n",
        "d.we got very high(3) price precision 91% of and recall of 94% and f1-score of 92%."
      ],
      "metadata": {
        "id": "L1wQR8J2o8Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(xgb, param_grid={'n_estimators': (10, 200), 'learning_rate': [1, 0.5, 0.1, 0.01, 0.001], 'max_depth': (5, 10),\n",
        "                                     'gamma': [1.5, 1.8], 'subsample': [0.3, 0.5, 0.8]}, cv = 5, scoring = 'accuracy', verbose = 10)\n",
        "grid.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "xs-PRb4WpAli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a72e61f-7e2a-4317-cca4-47c05968105f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "[CV 1/5; 1/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 1/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.837 total time=   0.1s\n",
            "[CV 2/5; 1/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 1/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.820 total time=   0.2s\n",
            "[CV 3/5; 1/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 1/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.853 total time=   0.9s\n",
            "[CV 4/5; 1/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 1/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.837 total time=   0.1s\n",
            "[CV 5/5; 1/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 1/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.2s\n",
            "[CV 1/5; 2/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 2/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 2/5; 2/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 2/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 3/5; 2/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 2/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.893 total time=   0.1s\n",
            "[CV 4/5; 2/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 2/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 5/5; 2/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 2/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 1/5; 3/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 3/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 2/5; 3/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 3/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 3/5; 3/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 3/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.887 total time=   0.1s\n",
            "[CV 4/5; 3/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 3/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 5/5; 3/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 3/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.897 total time=   0.1s\n",
            "[CV 1/5; 4/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 4/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.857 total time=   1.0s\n",
            "[CV 2/5; 4/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 4/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.830 total time=   1.1s\n",
            "[CV 3/5; 4/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 4/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.857 total time=   0.9s\n",
            "[CV 4/5; 4/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 4/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.827 total time=   0.9s\n",
            "[CV 5/5; 4/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 4/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.850 total time=   1.0s\n",
            "[CV 1/5; 5/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 5/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.850 total time=   1.3s\n",
            "[CV 2/5; 5/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 5/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.867 total time=   1.3s\n",
            "[CV 3/5; 5/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 5/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.3s\n",
            "[CV 4/5; 5/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 5/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.877 total time=   4.3s\n",
            "[CV 5/5; 5/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 5/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.3s\n",
            "[CV 1/5; 6/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 6/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.887 total time=   1.4s\n",
            "[CV 2/5; 6/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 6/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.903 total time=   1.4s\n",
            "[CV 3/5; 6/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 6/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.893 total time=   1.4s\n",
            "[CV 4/5; 6/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 6/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.880 total time=   1.5s\n",
            "[CV 5/5; 6/120] START gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 6/120] END gamma=1.5, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.907 total time=   1.4s\n",
            "[CV 1/5; 7/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 7/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.833 total time=   0.1s\n",
            "[CV 2/5; 7/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 7/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 7/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 7/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.857 total time=   0.1s\n",
            "[CV 4/5; 7/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 7/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.813 total time=   0.1s\n",
            "[CV 5/5; 7/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 7/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 1/5; 8/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 8/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 8/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 8/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.893 total time=   0.1s\n",
            "[CV 3/5; 8/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 8/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.887 total time=   0.1s\n",
            "[CV 4/5; 8/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 8/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.903 total time=   0.1s\n",
            "[CV 5/5; 8/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 8/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.887 total time=   0.1s\n",
            "[CV 1/5; 9/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 9/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.3s\n",
            "[CV 2/5; 9/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 9/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.907 total time=   0.3s\n",
            "[CV 3/5; 9/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 9/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.900 total time=   1.7s\n",
            "[CV 4/5; 9/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 9/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.9s\n",
            "[CV 5/5; 9/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 9/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.4s\n",
            "[CV 1/5; 10/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 10/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.830 total time=   1.0s\n",
            "[CV 2/5; 10/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 10/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.870 total time=   1.1s\n",
            "[CV 3/5; 10/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 10/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.0s\n",
            "[CV 4/5; 10/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 10/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.0s\n",
            "[CV 5/5; 10/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 10/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.0s\n",
            "[CV 1/5; 11/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 11/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.867 total time=   1.6s\n",
            "[CV 2/5; 11/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 11/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.900 total time=   1.6s\n",
            "[CV 3/5; 11/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 11/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.6s\n",
            "[CV 4/5; 11/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 11/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.890 total time=   4.5s\n",
            "[CV 5/5; 11/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 11/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.887 total time=   1.6s\n",
            "[CV 1/5; 12/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 12/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.890 total time=   2.1s\n",
            "[CV 2/5; 12/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 12/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.910 total time=   2.0s\n",
            "[CV 3/5; 12/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 12/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.907 total time=   2.1s\n",
            "[CV 4/5; 12/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 12/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   5.0s\n",
            "[CV 5/5; 12/120] START gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 12/120] END gamma=1.5, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.887 total time=   2.1s\n",
            "[CV 1/5; 13/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 13/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 13/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 13/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.877 total time=   0.1s\n",
            "[CV 3/5; 13/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 13/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.873 total time=   0.1s\n",
            "[CV 4/5; 13/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 13/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.857 total time=   0.1s\n",
            "[CV 5/5; 13/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 13/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.883 total time=   0.1s\n",
            "[CV 1/5; 14/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 14/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 2/5; 14/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 14/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 3/5; 14/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 14/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.893 total time=   0.1s\n",
            "[CV 4/5; 14/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 14/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 5/5; 14/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 14/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.903 total time=   0.1s\n",
            "[CV 1/5; 15/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 15/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.1s\n",
            "[CV 2/5; 15/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 15/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.897 total time=   0.1s\n",
            "[CV 3/5; 15/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 15/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 4/5; 15/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 15/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 5/5; 15/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 15/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.907 total time=   0.1s\n",
            "[CV 1/5; 16/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 16/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.850 total time=   1.0s\n",
            "[CV 2/5; 16/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 16/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.0s\n",
            "[CV 3/5; 16/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 16/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.890 total time=   1.0s\n",
            "[CV 4/5; 16/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 16/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.860 total time=   1.0s\n",
            "[CV 5/5; 16/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 16/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.897 total time=   1.0s\n",
            "[CV 1/5; 17/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 17/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.863 total time=   1.7s\n",
            "[CV 2/5; 17/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 17/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.890 total time=   3.9s\n",
            "[CV 3/5; 17/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 17/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.900 total time=   1.3s\n",
            "[CV 4/5; 17/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 17/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.887 total time=   1.3s\n",
            "[CV 5/5; 17/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 17/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.917 total time=   1.3s\n",
            "[CV 1/5; 18/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 18/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.877 total time=   1.5s\n",
            "[CV 2/5; 18/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 18/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.897 total time=   1.5s\n",
            "[CV 3/5; 18/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 18/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.883 total time=   1.5s\n",
            "[CV 4/5; 18/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 18/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.893 total time=   4.3s\n",
            "[CV 5/5; 18/120] START gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 18/120] END gamma=1.5, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.920 total time=   1.4s\n",
            "[CV 1/5; 19/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 19/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.843 total time=   0.1s\n",
            "[CV 2/5; 19/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 19/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.853 total time=   0.1s\n",
            "[CV 3/5; 19/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 19/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.873 total time=   0.1s\n",
            "[CV 4/5; 19/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 19/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.863 total time=   0.1s\n",
            "[CV 5/5; 19/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 19/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.873 total time=   0.1s\n",
            "[CV 1/5; 20/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 20/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.837 total time=   0.1s\n",
            "[CV 2/5; 20/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 20/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 3/5; 20/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 20/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.913 total time=   0.1s\n",
            "[CV 4/5; 20/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 20/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 5/5; 20/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 20/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.890 total time=   0.1s\n",
            "[CV 1/5; 21/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 21/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 2/5; 21/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 21/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.913 total time=   0.1s\n",
            "[CV 3/5; 21/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 21/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.900 total time=   0.1s\n",
            "[CV 4/5; 21/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 21/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.893 total time=   0.1s\n",
            "[CV 5/5; 21/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 21/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.900 total time=   0.1s\n",
            "[CV 1/5; 22/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 22/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.870 total time=   1.2s\n",
            "[CV 2/5; 22/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 22/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.2s\n",
            "[CV 3/5; 22/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 22/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.897 total time=   1.2s\n",
            "[CV 4/5; 22/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 22/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.2s\n",
            "[CV 5/5; 22/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 22/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.2s\n",
            "[CV 1/5; 23/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 23/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.867 total time=   4.6s\n",
            "[CV 2/5; 23/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 23/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.903 total time=   1.7s\n",
            "[CV 3/5; 23/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 23/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.927 total time=   1.8s\n",
            "[CV 4/5; 23/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 23/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.7s\n",
            "[CV 5/5; 23/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 23/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.900 total time=   1.8s\n",
            "[CV 1/5; 24/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 24/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.877 total time=   2.2s\n",
            "[CV 2/5; 24/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 24/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.903 total time=   5.1s\n",
            "[CV 3/5; 24/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 24/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.903 total time=   2.2s\n",
            "[CV 4/5; 24/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 24/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.897 total time=   2.2s\n",
            "[CV 5/5; 24/120] START gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 24/120] END gamma=1.5, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.910 total time=   2.2s\n",
            "[CV 1/5; 25/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 25/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 2/5; 25/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 25/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 3/5; 25/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 25/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 4/5; 25/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 25/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 5/5; 25/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 25/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 1/5; 26/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 26/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.847 total time=   0.1s\n",
            "[CV 2/5; 26/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 26/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 26/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 26/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 4/5; 26/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 26/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 5/5; 26/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 26/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 1/5; 27/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 27/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.847 total time=   0.1s\n",
            "[CV 2/5; 27/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 27/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.1s\n",
            "[CV 3/5; 27/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 27/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 4/5; 27/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 27/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 5/5; 27/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 27/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 28/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 28/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.880 total time=   2.4s\n",
            "[CV 2/5; 28/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 28/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.880 total time=   2.7s\n",
            "[CV 3/5; 28/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 28/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.920 total time=   1.1s\n",
            "[CV 4/5; 28/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 28/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.887 total time=   1.1s\n",
            "[CV 5/5; 28/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 28/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.907 total time=   1.1s\n",
            "[CV 1/5; 29/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 29/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.4s\n",
            "[CV 2/5; 29/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 29/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.907 total time=   1.4s\n",
            "[CV 3/5; 29/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 29/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.927 total time=   1.4s\n",
            "[CV 4/5; 29/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 29/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.3s\n",
            "[CV 5/5; 29/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 29/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.910 total time=   4.3s\n",
            "[CV 1/5; 30/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 30/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.883 total time=   1.5s\n",
            "[CV 2/5; 30/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 30/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.910 total time=   1.5s\n",
            "[CV 3/5; 30/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 30/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.903 total time=   1.5s\n",
            "[CV 4/5; 30/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 30/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.893 total time=   1.5s\n",
            "[CV 5/5; 30/120] START gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 30/120] END gamma=1.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.917 total time=   1.5s\n",
            "[CV 1/5; 31/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 31/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.843 total time=   0.1s\n",
            "[CV 2/5; 31/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 31/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 3/5; 31/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 31/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 4/5; 31/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 31/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.820 total time=   0.1s\n",
            "[CV 5/5; 31/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 31/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.870 total time=   0.1s\n",
            "[CV 1/5; 32/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 32/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 2/5; 32/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 32/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 3/5; 32/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 32/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.883 total time=   0.1s\n",
            "[CV 4/5; 32/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 32/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 5/5; 32/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 32/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.883 total time=   0.1s\n",
            "[CV 1/5; 33/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 33/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.863 total time=   0.1s\n",
            "[CV 2/5; 33/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 33/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.890 total time=   0.1s\n",
            "[CV 3/5; 33/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 33/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.890 total time=   0.1s\n",
            "[CV 4/5; 33/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 33/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 5/5; 33/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 33/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 34/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 34/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   4.3s\n",
            "[CV 2/5; 34/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 34/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.880 total time=   1.4s\n",
            "[CV 3/5; 34/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 34/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.917 total time=   1.4s\n",
            "[CV 4/5; 34/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 34/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.890 total time=   1.4s\n",
            "[CV 5/5; 34/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 34/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.917 total time=   1.4s\n",
            "[CV 1/5; 35/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 35/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.9s\n",
            "[CV 2/5; 35/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 35/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.907 total time=   1.8s\n",
            "[CV 3/5; 35/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 35/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.920 total time=   4.7s\n",
            "[CV 4/5; 35/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 35/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.890 total time=   1.8s\n",
            "[CV 5/5; 35/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 35/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.920 total time=   1.9s\n",
            "[CV 1/5; 36/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 36/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   2.2s\n",
            "[CV 2/5; 36/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 36/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.907 total time=   2.3s\n",
            "[CV 3/5; 36/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 36/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.897 total time=   5.1s\n",
            "[CV 4/5; 36/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 36/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.893 total time=   2.3s\n",
            "[CV 5/5; 36/120] START gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 36/120] END gamma=1.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.903 total time=   2.3s\n",
            "[CV 1/5; 37/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 37/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.807 total time=   0.1s\n",
            "[CV 2/5; 37/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 37/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.807 total time=   0.1s\n",
            "[CV 3/5; 37/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 37/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.830 total time=   0.1s\n",
            "[CV 4/5; 37/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 37/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.787 total time=   0.1s\n",
            "[CV 5/5; 37/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 37/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.843 total time=   0.1s\n",
            "[CV 1/5; 38/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 38/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.827 total time=   0.1s\n",
            "[CV 2/5; 38/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 38/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 3/5; 38/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 38/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 4/5; 38/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 38/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 5/5; 38/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 38/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.843 total time=   0.1s\n",
            "[CV 1/5; 39/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 39/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 2/5; 39/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 39/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.863 total time=   0.1s\n",
            "[CV 3/5; 39/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 39/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 4/5; 39/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 39/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.863 total time=   0.1s\n",
            "[CV 5/5; 39/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 39/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 1/5; 40/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 40/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.1s\n",
            "[CV 2/5; 40/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 40/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.847 total time=   1.2s\n",
            "[CV 3/5; 40/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 40/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.883 total time=   1.0s\n",
            "[CV 4/5; 40/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 40/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.867 total time=   4.1s\n",
            "[CV 5/5; 40/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 40/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.860 total time=   1.1s\n",
            "[CV 1/5; 41/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 41/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.860 total time=   1.4s\n",
            "[CV 2/5; 41/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 41/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.4s\n",
            "[CV 3/5; 41/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 41/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.903 total time=   1.4s\n",
            "[CV 4/5; 41/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 41/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.883 total time=   1.3s\n",
            "[CV 5/5; 41/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 41/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.4s\n",
            "[CV 1/5; 42/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 42/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.870 total time=   1.7s\n",
            "[CV 2/5; 42/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 42/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.873 total time=   4.3s\n",
            "[CV 3/5; 42/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 42/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.897 total time=   1.5s\n",
            "[CV 4/5; 42/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 42/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.877 total time=   1.5s\n",
            "[CV 5/5; 42/120] START gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 42/120] END gamma=1.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.873 total time=   1.5s\n",
            "[CV 1/5; 43/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 43/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 2/5; 43/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 43/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.813 total time=   0.1s\n",
            "[CV 3/5; 43/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 43/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.833 total time=   0.1s\n",
            "[CV 4/5; 43/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 43/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.800 total time=   0.1s\n",
            "[CV 5/5; 43/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 43/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.863 total time=   0.1s\n",
            "[CV 1/5; 44/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 44/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 44/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 44/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 3/5; 44/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 44/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 4/5; 44/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 44/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 44/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 44/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 1/5; 45/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 45/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 45/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 45/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 3/5; 45/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 45/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.890 total time=   0.1s\n",
            "[CV 4/5; 45/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 45/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.870 total time=   0.1s\n",
            "[CV 5/5; 45/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 45/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 46/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 46/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.4s\n",
            "[CV 2/5; 46/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 46/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.853 total time=   1.4s\n",
            "[CV 3/5; 46/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 46/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.890 total time=   4.3s\n",
            "[CV 4/5; 46/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 46/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.4s\n",
            "[CV 5/5; 46/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 46/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.4s\n",
            "[CV 1/5; 47/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 47/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.863 total time=   1.9s\n",
            "[CV 2/5; 47/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 47/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.9s\n",
            "[CV 3/5; 47/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 47/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.907 total time=   1.9s\n",
            "[CV 4/5; 47/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 47/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.880 total time=   4.8s\n",
            "[CV 5/5; 47/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 47/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.890 total time=   1.9s\n",
            "[CV 1/5; 48/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 48/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.863 total time=   2.2s\n",
            "[CV 2/5; 48/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 48/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.887 total time=   2.2s\n",
            "[CV 3/5; 48/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 48/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.897 total time=   2.2s\n",
            "[CV 4/5; 48/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 48/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.880 total time=   5.2s\n",
            "[CV 5/5; 48/120] START gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 48/120] END gamma=1.5, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.890 total time=   2.3s\n",
            "[CV 1/5; 49/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 49/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.800 total time=   0.1s\n",
            "[CV 2/5; 49/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 49/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.813 total time=   0.1s\n",
            "[CV 3/5; 49/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 49/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.830 total time=   0.1s\n",
            "[CV 4/5; 49/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 49/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.790 total time=   0.1s\n",
            "[CV 5/5; 49/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 49/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 1/5; 50/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 50/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.827 total time=   0.1s\n",
            "[CV 2/5; 50/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 50/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.853 total time=   0.1s\n",
            "[CV 3/5; 50/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 50/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 4/5; 50/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 50/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 5/5; 50/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 50/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.833 total time=   0.1s\n",
            "[CV 1/5; 51/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 51/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 51/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 51/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 51/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 51/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 4/5; 51/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 51/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 5/5; 51/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 51/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 1/5; 52/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 52/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.837 total time=   1.1s\n",
            "[CV 2/5; 52/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 52/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.820 total time=   1.1s\n",
            "[CV 3/5; 52/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 52/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.1s\n",
            "[CV 4/5; 52/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 52/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.827 total time=   1.1s\n",
            "[CV 5/5; 52/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 52/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.850 total time=   4.0s\n",
            "[CV 1/5; 53/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 53/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.850 total time=   1.4s\n",
            "[CV 2/5; 53/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 53/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.853 total time=   1.4s\n",
            "[CV 3/5; 53/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 53/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.4s\n",
            "[CV 4/5; 53/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 53/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.860 total time=   1.4s\n",
            "[CV 5/5; 53/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 53/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.853 total time=   1.4s\n",
            "[CV 1/5; 54/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 54/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.857 total time=   1.5s\n",
            "[CV 2/5; 54/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 54/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.860 total time=   1.9s\n",
            "[CV 3/5; 54/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 54/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.883 total time=   4.1s\n",
            "[CV 4/5; 54/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 54/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.867 total time=   1.5s\n",
            "[CV 5/5; 54/120] START gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 54/120] END gamma=1.5, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.853 total time=   1.5s\n",
            "[CV 1/5; 55/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 55/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.807 total time=   0.1s\n",
            "[CV 2/5; 55/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 55/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 3/5; 55/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 55/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.840 total time=   0.1s\n",
            "[CV 4/5; 55/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 55/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.797 total time=   0.1s\n",
            "[CV 5/5; 55/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 55/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.853 total time=   0.1s\n",
            "[CV 1/5; 56/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 56/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.837 total time=   0.1s\n",
            "[CV 2/5; 56/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 56/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 56/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 56/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 4/5; 56/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 56/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 56/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 56/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 57/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 57/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 57/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 57/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 3/5; 57/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 57/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.887 total time=   0.1s\n",
            "[CV 4/5; 57/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 57/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 57/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 57/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 1/5; 58/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 58/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.4s\n",
            "[CV 2/5; 58/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 58/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.837 total time=   1.4s\n",
            "[CV 3/5; 58/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 58/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.863 total time=   1.4s\n",
            "[CV 4/5; 58/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 58/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.837 total time=   4.2s\n",
            "[CV 5/5; 58/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 58/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.853 total time=   1.4s\n",
            "[CV 1/5; 59/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 59/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.867 total time=   1.8s\n",
            "[CV 2/5; 59/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 59/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.860 total time=   1.8s\n",
            "[CV 3/5; 59/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 59/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.8s\n",
            "[CV 4/5; 59/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 59/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.867 total time=   1.8s\n",
            "[CV 5/5; 59/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 59/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.857 total time=   4.7s\n",
            "[CV 1/5; 60/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 60/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.853 total time=   2.2s\n",
            "[CV 2/5; 60/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 60/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   2.2s\n",
            "[CV 3/5; 60/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 60/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.880 total time=   2.2s\n",
            "[CV 4/5; 60/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 60/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   2.2s\n",
            "[CV 5/5; 60/120] START gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 60/120] END gamma=1.5, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.867 total time=   5.1s\n",
            "[CV 1/5; 61/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 61/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 2/5; 61/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 61/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.803 total time=   0.1s\n",
            "[CV 3/5; 61/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 61/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.857 total time=   0.1s\n",
            "[CV 4/5; 61/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 61/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.837 total time=   0.1s\n",
            "[CV 5/5; 61/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 61/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 62/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 62/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 62/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 62/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 3/5; 62/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 62/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 4/5; 62/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 62/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.863 total time=   0.1s\n",
            "[CV 5/5; 62/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 62/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 63/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 63/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.1s\n",
            "[CV 2/5; 63/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 63/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.897 total time=   0.1s\n",
            "[CV 3/5; 63/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 63/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.897 total time=   0.1s\n",
            "[CV 4/5; 63/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 63/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 5/5; 63/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 63/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.900 total time=   0.1s\n",
            "[CV 1/5; 64/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 64/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.857 total time=   1.0s\n",
            "[CV 2/5; 64/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 64/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.820 total time=   1.0s\n",
            "[CV 3/5; 64/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 64/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.860 total time=   1.0s\n",
            "[CV 4/5; 64/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 64/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.830 total time=   1.0s\n",
            "[CV 5/5; 64/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 64/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.0s\n",
            "[CV 1/5; 65/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 65/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.3s\n",
            "[CV 2/5; 65/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 65/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.873 total time=   1.3s\n",
            "[CV 3/5; 65/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 65/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.907 total time=   4.2s\n",
            "[CV 4/5; 65/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 65/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.3s\n",
            "[CV 5/5; 65/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 65/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.3s\n",
            "[CV 1/5; 66/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 66/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 66/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 66/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.900 total time=   1.5s\n",
            "[CV 3/5; 66/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 66/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.897 total time=   1.5s\n",
            "[CV 4/5; 66/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 66/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.877 total time=   1.4s\n",
            "[CV 5/5; 66/120] START gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 66/120] END gamma=1.8, learning_rate=1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.890 total time=   4.4s\n",
            "[CV 1/5; 67/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 67/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 67/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 67/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.833 total time=   0.1s\n",
            "[CV 3/5; 67/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 67/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.843 total time=   0.1s\n",
            "[CV 4/5; 67/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 67/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.853 total time=   0.1s\n",
            "[CV 5/5; 67/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 67/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 1/5; 68/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 68/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.853 total time=   0.1s\n",
            "[CV 2/5; 68/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 68/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 3/5; 68/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 68/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 4/5; 68/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 68/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 5/5; 68/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 68/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 69/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 69/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 2/5; 69/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 69/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 3/5; 69/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 69/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.913 total time=   0.1s\n",
            "[CV 4/5; 69/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 69/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 5/5; 69/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 69/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.870 total time=   0.1s\n",
            "[CV 1/5; 70/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 70/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.833 total time=   1.1s\n",
            "[CV 2/5; 70/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 70/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.1s\n",
            "[CV 3/5; 70/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 70/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.840 total time=   1.1s\n",
            "[CV 4/5; 70/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 70/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.1s\n",
            "[CV 5/5; 70/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 70/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.870 total time=   1.1s\n",
            "[CV 1/5; 71/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 71/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.863 total time=   1.6s\n",
            "[CV 2/5; 71/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 71/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.867 total time=   4.5s\n",
            "[CV 3/5; 71/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 71/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.883 total time=   1.6s\n",
            "[CV 4/5; 71/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 71/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.873 total time=   1.7s\n",
            "[CV 5/5; 71/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 71/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.6s\n",
            "[CV 1/5; 72/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 72/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   2.1s\n",
            "[CV 2/5; 72/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 72/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.880 total time=   2.1s\n",
            "[CV 3/5; 72/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 72/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.907 total time=   5.0s\n",
            "[CV 4/5; 72/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 72/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.870 total time=   2.2s\n",
            "[CV 5/5; 72/120] START gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 72/120] END gamma=1.8, learning_rate=1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.897 total time=   2.1s\n",
            "[CV 1/5; 73/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 73/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 2/5; 73/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 73/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.870 total time=   0.1s\n",
            "[CV 3/5; 73/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 73/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.867 total time=   0.1s\n",
            "[CV 4/5; 73/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 73/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 5/5; 73/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 73/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.3;, score=0.887 total time=   0.1s\n",
            "[CV 1/5; 74/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 74/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 74/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 74/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.893 total time=   0.1s\n",
            "[CV 3/5; 74/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 74/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.910 total time=   0.1s\n",
            "[CV 4/5; 74/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 74/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 5/5; 74/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 74/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.5;, score=0.907 total time=   0.1s\n",
            "[CV 1/5; 75/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 75/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 2/5; 75/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 75/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.890 total time=   0.1s\n",
            "[CV 3/5; 75/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 75/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.893 total time=   0.1s\n",
            "[CV 4/5; 75/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 75/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.870 total time=   0.1s\n",
            "[CV 5/5; 75/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 75/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=10, subsample=0.8;, score=0.900 total time=   0.1s\n",
            "[CV 1/5; 76/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 76/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.863 total time=   1.1s\n",
            "[CV 2/5; 76/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 76/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.887 total time=   1.0s\n",
            "[CV 3/5; 76/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 76/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.897 total time=   1.0s\n",
            "[CV 4/5; 76/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 76/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.880 total time=   4.0s\n",
            "[CV 5/5; 76/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 76/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.3;, score=0.890 total time=   1.0s\n",
            "[CV 1/5; 77/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 77/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.883 total time=   1.4s\n",
            "[CV 2/5; 77/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 77/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.900 total time=   1.4s\n",
            "[CV 3/5; 77/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 77/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.920 total time=   1.3s\n",
            "[CV 4/5; 77/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 77/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.890 total time=   1.4s\n",
            "[CV 5/5; 77/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 77/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.5;, score=0.920 total time=   1.3s\n",
            "[CV 1/5; 78/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 78/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.887 total time=   1.5s\n",
            "[CV 2/5; 78/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 78/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.897 total time=   4.4s\n",
            "[CV 3/5; 78/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 78/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.890 total time=   1.4s\n",
            "[CV 4/5; 78/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 78/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.883 total time=   1.5s\n",
            "[CV 5/5; 78/120] START gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 78/120] END gamma=1.8, learning_rate=0.5, max_depth=5, n_estimators=200, subsample=0.8;, score=0.917 total time=   1.5s\n",
            "[CV 1/5; 79/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 79/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 2/5; 79/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 79/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.870 total time=   0.1s\n",
            "[CV 3/5; 79/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 79/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.863 total time=   0.1s\n",
            "[CV 4/5; 79/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 79/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.853 total time=   0.1s\n",
            "[CV 5/5; 79/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 79/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 80/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 80/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 80/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 80/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.883 total time=   0.1s\n",
            "[CV 3/5; 80/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 80/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.900 total time=   0.1s\n",
            "[CV 4/5; 80/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 80/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 5/5; 80/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 80/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.5;, score=0.903 total time=   0.1s\n",
            "[CV 1/5; 81/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 81/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.863 total time=   0.1s\n",
            "[CV 2/5; 81/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 81/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.907 total time=   0.1s\n",
            "[CV 3/5; 81/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 81/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.903 total time=   0.1s\n",
            "[CV 4/5; 81/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 81/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 5/5; 81/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 81/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=10, subsample=0.8;, score=0.910 total time=   0.1s\n",
            "[CV 1/5; 82/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 82/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.860 total time=   1.2s\n",
            "[CV 2/5; 82/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 82/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.867 total time=   1.2s\n",
            "[CV 3/5; 82/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 82/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.880 total time=   1.5s\n",
            "[CV 4/5; 82/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 82/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.863 total time=   4.0s\n",
            "[CV 5/5; 82/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 82/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.3s\n",
            "[CV 1/5; 83/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 83/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.863 total time=   1.8s\n",
            "[CV 2/5; 83/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 83/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.900 total time=   1.8s\n",
            "[CV 3/5; 83/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 83/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.907 total time=   1.8s\n",
            "[CV 4/5; 83/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 83/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.887 total time=   1.7s\n",
            "[CV 5/5; 83/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 83/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.5;, score=0.913 total time=   4.7s\n",
            "[CV 1/5; 84/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 84/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.880 total time=   2.3s\n",
            "[CV 2/5; 84/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 84/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.913 total time=   2.2s\n",
            "[CV 3/5; 84/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 84/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.907 total time=   2.3s\n",
            "[CV 4/5; 84/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 84/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.890 total time=   2.3s\n",
            "[CV 5/5; 84/120] START gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 84/120] END gamma=1.8, learning_rate=0.5, max_depth=10, n_estimators=200, subsample=0.8;, score=0.917 total time=   5.2s\n",
            "[CV 1/5; 85/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 85/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 2/5; 85/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 85/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 3/5; 85/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 85/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 4/5; 85/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 85/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.810 total time=   0.1s\n",
            "[CV 5/5; 85/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 85/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 1/5; 86/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 86/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.840 total time=   0.1s\n",
            "[CV 2/5; 86/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 86/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 86/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 86/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 4/5; 86/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 86/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 5/5; 86/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 86/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.5;, score=0.847 total time=   0.1s\n",
            "[CV 1/5; 87/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 87/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 87/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 87/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.1s\n",
            "[CV 3/5; 87/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 87/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.893 total time=   0.1s\n",
            "[CV 4/5; 87/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 87/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 5/5; 87/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 87/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 88/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 88/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.887 total time=   1.1s\n",
            "[CV 2/5; 88/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 88/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.893 total time=   1.1s\n",
            "[CV 3/5; 88/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 88/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.910 total time=   1.1s\n",
            "[CV 4/5; 88/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 88/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.900 total time=   1.1s\n",
            "[CV 5/5; 88/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 88/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.3;, score=0.900 total time=   1.1s\n",
            "[CV 1/5; 89/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 89/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.3s\n",
            "[CV 2/5; 89/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 89/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.897 total time=   4.2s\n",
            "[CV 3/5; 89/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 89/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.927 total time=   1.4s\n",
            "[CV 4/5; 89/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 89/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.4s\n",
            "[CV 5/5; 89/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 89/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5;, score=0.910 total time=   1.3s\n",
            "[CV 1/5; 90/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 90/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.880 total time=   1.5s\n",
            "[CV 2/5; 90/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 90/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.913 total time=   1.5s\n",
            "[CV 3/5; 90/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 90/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.903 total time=   1.5s\n",
            "[CV 4/5; 90/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 90/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.897 total time=   4.4s\n",
            "[CV 5/5; 90/120] START gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 90/120] END gamma=1.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.923 total time=   1.5s\n",
            "[CV 1/5; 91/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 91/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.840 total time=   0.1s\n",
            "[CV 2/5; 91/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 91/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.827 total time=   0.1s\n",
            "[CV 3/5; 91/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 91/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 4/5; 91/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 91/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.823 total time=   0.1s\n",
            "[CV 5/5; 91/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 91/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.3;, score=0.850 total time=   0.1s\n",
            "[CV 1/5; 92/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 92/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 2/5; 92/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 92/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 92/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 92/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.883 total time=   0.1s\n",
            "[CV 4/5; 92/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 92/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.883 total time=   0.1s\n",
            "[CV 5/5; 92/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 92/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.5;, score=0.873 total time=   0.1s\n",
            "[CV 1/5; 93/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 93/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 2/5; 93/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 93/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.883 total time=   0.1s\n",
            "[CV 3/5; 93/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 93/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.897 total time=   0.1s\n",
            "[CV 4/5; 93/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 93/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.887 total time=   0.1s\n",
            "[CV 5/5; 93/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 93/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 1/5; 94/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 94/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.873 total time=   1.4s\n",
            "[CV 2/5; 94/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 94/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.893 total time=   1.4s\n",
            "[CV 3/5; 94/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 94/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.903 total time=   1.4s\n",
            "[CV 4/5; 94/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 94/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.883 total time=   1.4s\n",
            "[CV 5/5; 94/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 94/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.3;, score=0.917 total time=   4.0s\n",
            "[CV 1/5; 95/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 95/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.873 total time=   2.2s\n",
            "[CV 2/5; 95/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 95/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.910 total time=   1.9s\n",
            "[CV 3/5; 95/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 95/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.923 total time=   1.9s\n",
            "[CV 4/5; 95/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 95/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.887 total time=   1.9s\n",
            "[CV 5/5; 95/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 95/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.5;, score=0.920 total time=   1.9s\n",
            "[CV 1/5; 96/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 96/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   5.2s\n",
            "[CV 2/5; 96/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 96/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.907 total time=   2.3s\n",
            "[CV 3/5; 96/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 96/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.900 total time=   2.3s\n",
            "[CV 4/5; 96/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 96/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.900 total time=   2.3s\n",
            "[CV 5/5; 96/120] START gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 96/120] END gamma=1.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8;, score=0.900 total time=   5.3s\n",
            "[CV 1/5; 97/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 97/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.807 total time=   0.1s\n",
            "[CV 2/5; 97/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 97/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.807 total time=   0.1s\n",
            "[CV 3/5; 97/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 97/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.830 total time=   0.1s\n",
            "[CV 4/5; 97/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 97/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.793 total time=   0.1s\n",
            "[CV 5/5; 97/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 97/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 1/5; 98/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 98/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.820 total time=   0.1s\n",
            "[CV 2/5; 98/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 98/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 3/5; 98/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 98/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 4/5; 98/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 98/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 5/5; 98/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 98/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.5;, score=0.843 total time=   0.1s\n",
            "[CV 1/5; 99/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 99/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.857 total time=   0.1s\n",
            "[CV 2/5; 99/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 99/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 3/5; 99/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 99/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.1s\n",
            "[CV 4/5; 99/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 99/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.863 total time=   0.1s\n",
            "[CV 5/5; 99/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 99/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 100/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 100/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.837 total time=   1.1s\n",
            "[CV 2/5; 100/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 100/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.1s\n",
            "[CV 3/5; 100/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 100/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.877 total time=   1.1s\n",
            "[CV 4/5; 100/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 100/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.857 total time=   1.1s\n",
            "[CV 5/5; 100/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 100/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.3;, score=0.863 total time=   1.1s\n",
            "[CV 1/5; 101/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 101/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.857 total time=   1.4s\n",
            "[CV 2/5; 101/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 101/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.873 total time=   1.4s\n",
            "[CV 3/5; 101/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 101/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.903 total time=   4.3s\n",
            "[CV 4/5; 101/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 101/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.880 total time=   1.3s\n",
            "[CV 5/5; 101/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 101/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.3s\n",
            "[CV 1/5; 102/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 102/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.870 total time=   1.5s\n",
            "[CV 2/5; 102/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 102/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.867 total time=   1.5s\n",
            "[CV 3/5; 102/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 102/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.893 total time=   1.5s\n",
            "[CV 4/5; 102/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 102/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.880 total time=   1.5s\n",
            "[CV 5/5; 102/120] START gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 102/120] END gamma=1.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.873 total time=   4.4s\n",
            "[CV 1/5; 103/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 103/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 2/5; 103/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 103/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.817 total time=   0.1s\n",
            "[CV 3/5; 103/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 103/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.833 total time=   0.1s\n",
            "[CV 4/5; 103/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 103/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.793 total time=   0.1s\n",
            "[CV 5/5; 103/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 103/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.3;, score=0.867 total time=   0.1s\n",
            "[CV 1/5; 104/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 104/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.840 total time=   0.1s\n",
            "[CV 2/5; 104/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 104/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.863 total time=   0.1s\n",
            "[CV 3/5; 104/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 104/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 4/5; 104/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 104/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 104/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 104/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.5;, score=0.857 total time=   0.1s\n",
            "[CV 1/5; 105/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 105/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.850 total time=   0.1s\n",
            "[CV 2/5; 105/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 105/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.873 total time=   0.1s\n",
            "[CV 3/5; 105/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 105/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.890 total time=   0.1s\n",
            "[CV 4/5; 105/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 105/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 105/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 105/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 106/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 106/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.840 total time=   1.4s\n",
            "[CV 2/5; 106/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 106/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.850 total time=   1.4s\n",
            "[CV 3/5; 106/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 106/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.887 total time=   1.4s\n",
            "[CV 4/5; 106/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 106/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.863 total time=   1.4s\n",
            "[CV 5/5; 106/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 106/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.3;, score=0.867 total time=   1.4s\n",
            "[CV 1/5; 107/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 107/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.863 total time=   4.7s\n",
            "[CV 2/5; 107/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 107/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.9s\n",
            "[CV 3/5; 107/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 107/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.903 total time=   1.9s\n",
            "[CV 4/5; 107/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 107/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.8s\n",
            "[CV 5/5; 107/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 107/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.5;, score=0.890 total time=   1.9s\n",
            "[CV 1/5; 108/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 108/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.867 total time=   2.5s\n",
            "[CV 2/5; 108/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 108/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.890 total time=   4.8s\n",
            "[CV 3/5; 108/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 108/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.893 total time=   2.3s\n",
            "[CV 4/5; 108/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 108/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.883 total time=   2.2s\n",
            "[CV 5/5; 108/120] START gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 108/120] END gamma=1.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8;, score=0.890 total time=   2.2s\n",
            "[CV 1/5; 109/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 109/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.800 total time=   0.1s\n",
            "[CV 2/5; 109/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 109/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.813 total time=   0.1s\n",
            "[CV 3/5; 109/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 109/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.830 total time=   0.1s\n",
            "[CV 4/5; 109/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 109/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.793 total time=   0.1s\n",
            "[CV 5/5; 109/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 109/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.3;, score=0.847 total time=   0.1s\n",
            "[CV 1/5; 110/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 110/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.820 total time=   0.1s\n",
            "[CV 2/5; 110/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 110/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 3/5; 110/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 110/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 4/5; 110/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 110/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.850 total time=   0.1s\n",
            "[CV 5/5; 110/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 110/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.5;, score=0.837 total time=   0.1s\n",
            "[CV 1/5; 111/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 111/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 2/5; 111/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 111/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 111/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 111/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.880 total time=   0.1s\n",
            "[CV 4/5; 111/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 111/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 5/5; 111/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 111/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 1/5; 112/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 112/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.833 total time=   4.0s\n",
            "[CV 2/5; 112/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 112/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.820 total time=   1.1s\n",
            "[CV 3/5; 112/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 112/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.843 total time=   1.1s\n",
            "[CV 4/5; 112/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 112/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.823 total time=   1.1s\n",
            "[CV 5/5; 112/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 112/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.3;, score=0.850 total time=   1.1s\n",
            "[CV 1/5; 113/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 113/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.853 total time=   1.4s\n",
            "[CV 2/5; 113/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 113/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.853 total time=   1.4s\n",
            "[CV 3/5; 113/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 113/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.877 total time=   1.4s\n",
            "[CV 4/5; 113/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 113/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.857 total time=   3.9s\n",
            "[CV 5/5; 113/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 113/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.5;, score=0.853 total time=   1.8s\n",
            "[CV 1/5; 114/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 114/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.857 total time=   1.6s\n",
            "[CV 2/5; 114/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 114/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.863 total time=   1.5s\n",
            "[CV 3/5; 114/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 114/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.880 total time=   1.5s\n",
            "[CV 4/5; 114/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 114/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.870 total time=   1.5s\n",
            "[CV 5/5; 114/120] START gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 114/120] END gamma=1.8, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.8;, score=0.853 total time=   1.6s\n",
            "[CV 1/5; 115/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 1/5; 115/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.803 total time=   0.1s\n",
            "[CV 2/5; 115/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 2/5; 115/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.820 total time=   0.1s\n",
            "[CV 3/5; 115/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 3/5; 115/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.837 total time=   0.1s\n",
            "[CV 4/5; 115/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 4/5; 115/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.800 total time=   0.1s\n",
            "[CV 5/5; 115/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3\n",
            "[CV 5/5; 115/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.3;, score=0.860 total time=   0.1s\n",
            "[CV 1/5; 116/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 1/5; 116/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.840 total time=   0.1s\n",
            "[CV 2/5; 116/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 2/5; 116/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.1s\n",
            "[CV 3/5; 116/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 3/5; 116/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.880 total time=   0.1s\n",
            "[CV 4/5; 116/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 4/5; 116/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.870 total time=   0.1s\n",
            "[CV 5/5; 116/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5\n",
            "[CV 5/5; 116/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.5;, score=0.860 total time=   0.2s\n",
            "[CV 1/5; 117/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 1/5; 117/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.860 total time=   0.3s\n",
            "[CV 2/5; 117/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 2/5; 117/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   2.8s\n",
            "[CV 3/5; 117/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 3/5; 117/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.877 total time=   0.2s\n",
            "[CV 4/5; 117/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 4/5; 117/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.867 total time=   0.1s\n",
            "[CV 5/5; 117/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8\n",
            "[CV 5/5; 117/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=10, subsample=0.8;, score=0.853 total time=   0.1s\n",
            "[CV 1/5; 118/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 1/5; 118/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.840 total time=   1.4s\n",
            "[CV 2/5; 118/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 2/5; 118/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.837 total time=   1.4s\n",
            "[CV 3/5; 118/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 3/5; 118/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.863 total time=   1.4s\n",
            "[CV 4/5; 118/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 4/5; 118/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.837 total time=   1.3s\n",
            "[CV 5/5; 118/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3\n",
            "[CV 5/5; 118/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.3;, score=0.857 total time=   1.4s\n",
            "[CV 1/5; 119/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 1/5; 119/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.8s\n",
            "[CV 2/5; 119/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 2/5; 119/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.860 total time=   4.8s\n",
            "[CV 3/5; 119/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 3/5; 119/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.897 total time=   1.9s\n",
            "[CV 4/5; 119/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 4/5; 119/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.870 total time=   1.8s\n",
            "[CV 5/5; 119/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5\n",
            "[CV 5/5; 119/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.5;, score=0.857 total time=   1.8s\n",
            "[CV 1/5; 120/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 1/5; 120/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.853 total time=   2.2s\n",
            "[CV 2/5; 120/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 2/5; 120/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.867 total time=   3.3s\n",
            "[CV 3/5; 120/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 3/5; 120/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.877 total time=   3.9s\n",
            "[CV 4/5; 120/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 4/5; 120/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.873 total time=   2.2s\n",
            "[CV 5/5; 120/120] START gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8\n",
            "[CV 5/5; 120/120] END gamma=1.8, learning_rate=0.001, max_depth=10, n_estimators=200, subsample=0.8;, score=0.860 total time=   2.2s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=0.1, m...\n",
              "                                     max_delta_step=None, max_depth=5,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None,\n",
              "                                     objective='multi:softprob', predictor=None, ...),\n",
              "             param_grid={'gamma': [1.5, 1.8],\n",
              "                         'learning_rate': [1, 0.5, 0.1, 0.01, 0.001],\n",
              "                         'max_depth': (5, 10), 'n_estimators': (10, 200),\n",
              "                         'subsample': [0.3, 0.5, 0.8]},\n",
              "             scoring='accuracy', verbose=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=0.1, m...\n",
              "                                     max_delta_step=None, max_depth=5,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None,\n",
              "                                     objective=&#x27;multi:softprob&#x27;, predictor=None, ...),\n",
              "             param_grid={&#x27;gamma&#x27;: [1.5, 1.8],\n",
              "                         &#x27;learning_rate&#x27;: [1, 0.5, 0.1, 0.01, 0.001],\n",
              "                         &#x27;max_depth&#x27;: (5, 10), &#x27;n_estimators&#x27;: (10, 200),\n",
              "                         &#x27;subsample&#x27;: [0.3, 0.5, 0.8]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=0.1, m...\n",
              "                                     max_delta_step=None, max_depth=5,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None,\n",
              "                                     objective=&#x27;multi:softprob&#x27;, predictor=None, ...),\n",
              "             param_grid={&#x27;gamma&#x27;: [1.5, 1.8],\n",
              "                         &#x27;learning_rate&#x27;: [1, 0.5, 0.1, 0.01, 0.001],\n",
              "                         &#x27;max_depth&#x27;: (5, 10), &#x27;n_estimators&#x27;: (10, 200),\n",
              "                         &#x27;subsample&#x27;: [0.3, 0.5, 0.8]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find best params value\n",
        "grid.best_params_"
      ],
      "metadata": {
        "id": "qSgF6uVQpDXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd983f1d-9224-44d2-dc6a-82764c854ad1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gamma': 1.5,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 5,\n",
              " 'n_estimators': 200,\n",
              " 'subsample': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find best estimeter\n",
        "grid.best_estimator_"
      ],
      "metadata": {
        "id": "ehiDSk3ppLSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "a4479f9d-10cd-424b-f559-e192012a188b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applying best estimeter value in xgboost\n",
        "model=XGBClassifier(gamma=1.5, max_depth=10, n_estimators=200,\n",
        "              objective='multi:softprob', subsample=0.5)\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "gGORUo3rpN_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "18163eed-1176-4d5e-8368-b68ff4759e3a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=1.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "# Get the predicted probabilities\n",
        "trainscore =  model.score(x_train,y_train)\n",
        "testscore =  model.score(x_test,y_test) \n",
        "print(\"train score: {}\".format(trainscore),'\\n')\n",
        "print(\"test score: {}\".format(testscore),'\\n')\n",
        "y_predxgb = model.predict(x_test)\n",
        "print(' f1 score: ',f1_score(y_test, y_predxgb,average='micro'),'\\n')\n",
        "\n",
        "# Get the confusion matrix for both train and test\n",
        "print(confusion_matrix(y_test, y_predxgb))"
      ],
      "metadata": {
        "id": "wdpv3O9hpRNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6edb93-0c36-42cb-b0dc-1d809d1a94b6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.988 \n",
            "\n",
            "test score: 0.904 \n",
            "\n",
            " f1 score:  0.904 \n",
            "\n",
            "[[122  10   0   0]\n",
            " [  2 101   6   0]\n",
            " [  0   9 100  10]\n",
            " [  0   0  11 129]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "print(' precision score: ',precision_score(y_test, y_predxgb,average='micro'),'\\n')\n",
        "print(' recall score: ',recall_score(y_test, y_predxgb,average='micro'),'\\n')\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for tuned XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "f8oCjHZupUR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ff343d-2071-4366-e786-ecf7e16f514c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " precision score:  0.904 \n",
            "\n",
            " recall score:  0.904 \n",
            "\n",
            "Classification Report for tuned XGBoost(Train set)= \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       368\n",
            "           1       1.00      1.00      1.00       391\n",
            "           2       1.00      1.00      1.00       381\n",
            "           3       1.00      1.00      1.00       360\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       1.00      1.00      1.00      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------- XGBoosting -------------------------------------\n",
        "probabilityValues = RFmodel.predict_proba(x)\n",
        "auc = roc_auc_score(y,probabilityValues,multi_class ='ovr')\n",
        "print(auc)"
      ],
      "metadata": {
        "id": "Al1uQbvhpW-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8e1c1b-a7db-4468-b2d1-cc7064a057ef"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9975116666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "D_90z0CypZ80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer :-\n",
        "\n",
        "GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "our goal should be to find the best hyperparameters values to get the perfect prediction results from our model. But the question arises, how to find these best sets of hyperparameters? One can try the Manual Search method, by using the hit and trial process and can find the best hyperparameters which would take huge time to build a single model.\n",
        "\n",
        "For this reason, methods like Random Search, GridSearch were introduced. Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved.\n",
        "\n",
        "In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n",
        "\n",
        "That's why we have used GridsearCV method for hyperparameter optimization."
      ],
      "metadata": {
        "id": "P-RfnEkgpfck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training score is 98% and testing score 89%.\n",
        "\n",
        "For testing dataset,\n",
        "\n",
        "a.we got low(0) price precision 100% of and recall of 100% and f1-score of 100%.\n",
        "\n",
        "b.we got medium(1) price precision 100% of and recall of 100% and f1-score of 81%.\n",
        "\n",
        "c.we got High(2) price precision 100% of and recall of 100% and f1-score of 100%.\n",
        "\n",
        "d.we got very high(3) price precision 100% of and recall of 100% and f1-score of 100%."
      ],
      "metadata": {
        "id": "wNrz-Tl5pj-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**finally we made result in cross validation of XGB classifier !!**"
      ],
      "metadata": {
        "id": "6p6qhbm5pm8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "7IRN3j2kprjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :- we have choosen XGBoost model and logistic regression which is hyperparameter optimized. first of all we need accuracy for the mobile price range prediction. Thus, for greater accuracy we used kernel SVM, Random Forest, XgBoost. So, we tried both logistic and XGBoost. Here is their ealuation metrics and we would like to compare."
      ],
      "metadata": {
        "id": "kg1DjGQ5pwe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!**"
      ],
      "metadata": {
        "id": "4Qtn3ilVp0Bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion :-**"
      ],
      "metadata": {
        "id": "4eQWvftBp8Jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we made it!!!\n",
        "\n",
        "In this article, we looked at classification. Classifiers represent the intersection of advanced machine theory and practical application. These algorithms are more than just a sorting mechanism for organising unlabeled data instances into distinct groupings. Classifiers include a unique set of dynamic rules that include an interpretation mechanism for dealing with ambiguous or unknown values, all of which are suited to the kind of inputs being analysed. Most classifiers also utilise probability estimates, which enable end-users to adjust data categorization using utility functions.\n",
        "\n",
        "From EDA we can see that here are mobile phones in 4 price ranges. The number of elements is almost similar.\n",
        "\n",
        "half the devices have Bluetooth, and half don’t\n",
        "\n",
        "there is a gradual increase in battery as the price range increases\n",
        "\n",
        "RAM has continuous increase with price range while moving from Low cost to Very high cost.\n",
        "\n",
        "costly phones are lighter.\n",
        "\n",
        "RAM, battery power, pixels played more significant role in deciding the price range of mobile phone.\n",
        "\n",
        "form all the above experiments we can conclude that XGboosting and linear regression with using hyperparameters we got the best results."
      ],
      "metadata": {
        "id": "J88gnwxUqArG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hurrah! You have successfully completed your Machine Learning Capstone Project !!!**"
      ],
      "metadata": {
        "id": "xNrZUz_AqEVe"
      }
    }
  ]
}